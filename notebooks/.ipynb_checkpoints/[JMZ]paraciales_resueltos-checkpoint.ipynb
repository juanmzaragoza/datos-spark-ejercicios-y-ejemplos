{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016_2c_parcial_1\n",
    "\n",
    "1) Contamos con un cluster que tiene 4 computadoras. Queremos\n",
    "aprovechar el paralelismo del cluster para calcular los números primos\n",
    "entre 2 y 20.000.000. Para esto usaremos el conocido algoritmo de la\n",
    "criba de Eratóstenes. Por ejemplo si empezamos con una lista de tipo\n",
    "(2,3,4,5,6,7,8...) en un primer paso eliminamos todos los que son\n",
    "mayores a 2 y divisibles por 2 y nos queda (2,3,5,7,9,11,13…) luego\n",
    "eliminamos todos los mayores a 3 divisibles por 3 y nos queda\n",
    "(2,3,5,7,11,13….etc) luego todos los divisibles por 5 y así\n",
    "sucesivamente. El resultado final es una lista de números que son\n",
    "primos. Programar este programa usando PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97,\n",
       " 101,\n",
       " 103,\n",
       " 107,\n",
       " 109,\n",
       " 113,\n",
       " 127,\n",
       " 131,\n",
       " 137,\n",
       " 139,\n",
       " 149,\n",
       " 151,\n",
       " 157,\n",
       " 163,\n",
       " 167,\n",
       " 173,\n",
       " 179,\n",
       " 181,\n",
       " 191,\n",
       " 193,\n",
       " 197,\n",
       " 199]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isDivisiblePor(x,y):\n",
    "    return ((x%y) == 0)\n",
    "\n",
    "data = range(2,200)\n",
    "rdd = sc.parallelize(data,4)\n",
    "\n",
    "prev = pivote = 1\n",
    "\n",
    "pivote = rdd.reduce(lambda x,y: x if (x > pivote and x < y) else y)\n",
    "while(pivote != prev):\n",
    "    rdd = rdd.filter(lambda x: (pivote>=x or (x>pivote and not isDivisiblePor(x,pivote)))).cache()\n",
    "    \n",
    "    prev = pivote\n",
    "    pivote = rdd.reduce(lambda x,y: x if (x > pivote and x < y) else y)\n",
    "    \n",
    "    \n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En este ejercicio queremos programar un sistema que recomiende\n",
    "textos a usuarios en base a sus gustos sobre ciertos términos (palabras).\n",
    "Se cuenta con un RDD de textos de la forma (docId, texto) donde texto\n",
    "es un string de longitud variable. Además contamos con un RDD que\n",
    "indica qué términos le gustan o no a cada usuario de la forma (userId,\n",
    "término, score) por ejemplo (23, “calesita”, -2). Se pide programar en\n",
    "Spark un programa que calcule el score total de cada documento para\n",
    "cada usuario generando un RDD de la forma (userId, docId, score) en\n",
    "donde el score es simplemente la suma de los scores del usuario para\n",
    "los términos que aparecen en el documento. Puede haber términos en\n",
    "los documentos para los cuales no exista score de algunos usuarios, en\n",
    "estos casos simplemente los consideramos neutros (score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2, 16), 1),\n",
       " ((1, 11), -1),\n",
       " ((2, 14), -1),\n",
       " ((5, 13), 5),\n",
       " ((2, 11), 0),\n",
       " ((3, 13), 3)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = [(11,'Esto es un texto de ejemplo'),\n",
    "          (12,'No tenes creatividad??'),\n",
    "          (13,'No elegir textos aleatorios como lorep isum!!!!'),\n",
    "          (14,'... y no se te cae ni una idea ...'),\n",
    "          (15,'En el parcial se veia complicad XD'),\n",
    "          (16,'Falta mucho?'),\n",
    "          (17,'Ultimo texto Ultimo texto ultimo texto')]\n",
    "\n",
    "terminos = [(1,'esto',-1),\n",
    "            (1,'creatividad',2),\n",
    "            (2,'esto',0),\n",
    "            (2,'falta',1),\n",
    "            (2,'y',-1),\n",
    "            (3,'aleatorios',3),\n",
    "            (3,'como',0),\n",
    "            (4,'puedo',-3),\n",
    "            (5,'textos',5)]\n",
    "\n",
    "def getTermsByDoc(terms,docId):\n",
    "    termsByDoc = []\n",
    "    for term in terms:\n",
    "        termsByDoc.append((term.lower(),docId))\n",
    "    return termsByDoc\n",
    "\n",
    "rddTextos = sc.parallelize(textos)\n",
    "rddTerminos = sc.parallelize(terminos)\n",
    "\n",
    "rddTextos = rddTextos.flatMap(lambda x: getTermsByDoc(x[1].split(),x[0]))\n",
    "#[('esto', 11),\n",
    "#('es', 11),\n",
    "#('un', 11),\n",
    "#('texto', 11),\n",
    "#('de', 11),\n",
    "#('ejemplo', 11),\n",
    "#('no', 12),\n",
    "#('tenes', 12),\n",
    "#('creatividad??', 12),\n",
    "\n",
    "rddTerminos = rddTerminos.map(lambda x: (x[1],(x[0],x[2])))\n",
    "#[('esto', (1, -1)),\n",
    "#('creatividad', (1, 2)),\n",
    "#('esto', (2, 0)),\n",
    "#('falta', (2, 1)),\n",
    "#('y', (2, -1)),\n",
    "#('aleatorios', (3, 3)),\n",
    "#('como', (3, 0)),\n",
    "#('puedo', (4, -3)),\n",
    "#('textos', (5, 5))]\n",
    "\n",
    "rddJoin = rddTextos.join(rddTerminos)\n",
    "#[('falta', (16, (2, 1))),\n",
    "#('y', (14, (2, -1))),\n",
    "#('puedo', (17, (4, -3))),\n",
    "#('como', (13, (3, 0))),\n",
    "#('aleatorios', (13, (3, 3))),\n",
    "#('textos', (13, (5, 5))),\n",
    "#('esto', (11, (1, -1))),\n",
    "#('esto', (11, (2, 0)))]\n",
    "\n",
    "rddJoin.map(lambda x: ((x[1][1][0],x[1][0]),x[1][1][1])).reduceByKey(lambda x,y: x+y).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 2014_1c_Parcial_3op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1) Se tiene una colección de textos almacenados en un cluster.\n",
    "Se quiere construir un índice invertido para la colección\n",
    "completa. Programar usando Map-Reduce la construcción del\n",
    "índice usando el esquema Tf-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', [(5, 1)], 2.08),\n",
       " ('si', [(5, 1)], 2.08),\n",
       " ('cae', [(4, 1)], 2.08),\n",
       " ('isum!!!!', [(3, 1)], 2.08),\n",
       " ('lo', [(5, 1)], 2.08),\n",
       " ('ni', [(4, 1)], 2.08),\n",
       " ('ultimo', [(7, 3)], 2.08),\n",
       " ('idea', [(4, 1)], 2.08),\n",
       " ('como', [(3, 1)], 2.08),\n",
       " ('falta', [(6, 1)], 2.08),\n",
       " ('...', [(4, 1)], 2.08),\n",
       " ('no', [(2, 1), (5, 1), (4, 1), (3, 1)], 0.69),\n",
       " ('y', [(4, 1)], 2.08),\n",
       " ('se', [(5, 2), (4, 1)], 1.39),\n",
       " ('textos', [(3, 1)], 2.08),\n",
       " ('aleatorios', [(3, 1)], 2.08),\n",
       " ('una', [(4, 1)], 2.08),\n",
       " ('es', [(1, 1), (5, 1)], 1.39),\n",
       " ('ejemplo', [(1, 1)], 2.08),\n",
       " ('mucho?', [(6, 1)], 2.08),\n",
       " ('esto', [(1, 1)], 2.08),\n",
       " ('pero', [(5, 1)], 2.08),\n",
       " ('en', [(5, 1)], 2.08),\n",
       " ('lorep', [(3, 1)], 2.08),\n",
       " ('xd', [(5, 1)], 2.08),\n",
       " ('elegir', [(3, 1)], 2.08),\n",
       " ('parcial', [(5, 1)], 2.08),\n",
       " ('te', [(4, 1)], 2.08),\n",
       " ('creatividad??', [(2, 1)], 2.08),\n",
       " ('de', [(1, 1)], 2.08),\n",
       " ('veia', [(5, 1)], 2.08),\n",
       " ('texto', [(7, 3), (1, 1)], 1.39),\n",
       " ('un', [(1, 1)], 2.08),\n",
       " ('complicad', [(5, 1)], 2.08),\n",
       " ('tenes', [(2, 1)], 2.08)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "textos = [(1,'Esto es un texto de ejemplo'),\n",
    "          (2,'No tenes creatividad??'),\n",
    "          (3,'No elegir textos aleatorios como lorep isum!!!!'),\n",
    "          (4,'... y no se te cae ni una idea'),\n",
    "          (5,'En el parcial se veia complicad XD pero no se si lo es'),\n",
    "          (6,'Falta mucho?'),\n",
    "          (7,'Ultimo texto Ultimo texto Ultimo texto')]\n",
    "\n",
    "def getTermsByDoc(docId,tems):\n",
    "    terms = []\n",
    "    for term in tems:\n",
    "        terms.append(((term.lower(),docId),1))\n",
    "    return terms\n",
    "    \n",
    "rdd = sc.parallelize(textos)\n",
    "\n",
    "N = rdd.count()\n",
    "\n",
    "rdd.flatMap(lambda x: getTermsByDoc(x[0],x[1].split()))\\\n",
    "    .reduceByKey(lambda x,y: x+y).map(lambda x: (x[0][0],(x[0][1],x[1])))\\\n",
    "    .groupByKey()\\\n",
    "    .map(lambda x: (x[0],list(x[1]),round(log((N+1)/(len(list(x[1])))),2))).collect()\n",
    "#el resultado es una lista de terminos (el ii) donde: \n",
    "#el primer elemento es el termino\n",
    "#el segundo termino es un vector de tuplas, donde cada tupla es un id de documento y el tf de ese termino en ese documento\n",
    "#el tercero es el IDF de cada termin log(N+1/tfi) donde tfi es la cantidad de docs donde aparece el termino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
