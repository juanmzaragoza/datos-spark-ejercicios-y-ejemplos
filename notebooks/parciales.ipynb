{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "try: \n",
    "    type(sc)\n",
    "except NameError:\n",
    "    sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016_2c_parcial_1\n",
    "\n",
    "1) Contamos con un cluster que tiene 4 computadoras. Queremos\n",
    "aprovechar el paralelismo del cluster para calcular los números primos\n",
    "entre 2 y 20.000.000. Para esto usaremos el conocido algoritmo de la\n",
    "criba de Eratóstenes. Por ejemplo si empezamos con una lista de tipo\n",
    "(2,3,4,5,6,7,8...) en un primer paso eliminamos todos los que son\n",
    "mayores a 2 y divisibles por 2 y nos queda (2,3,5,7,9,11,13…) luego\n",
    "eliminamos todos los mayores a 3 divisibles por 3 y nos queda\n",
    "(2,3,5,7,11,13….etc) luego todos los divisibles por 5 y así\n",
    "sucesivamente. El resultado final es una lista de números que son\n",
    "primos. Programar este programa usando PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 23,\n",
       " 29,\n",
       " 31,\n",
       " 37,\n",
       " 41,\n",
       " 43,\n",
       " 47,\n",
       " 53,\n",
       " 59,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 73,\n",
       " 79,\n",
       " 83,\n",
       " 89,\n",
       " 97,\n",
       " 101,\n",
       " 103,\n",
       " 107,\n",
       " 109,\n",
       " 113,\n",
       " 127,\n",
       " 131,\n",
       " 137,\n",
       " 139,\n",
       " 149,\n",
       " 151,\n",
       " 157,\n",
       " 163,\n",
       " 167,\n",
       " 173,\n",
       " 179,\n",
       " 181,\n",
       " 191,\n",
       " 193,\n",
       " 197,\n",
       " 199]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isDivisiblePor(x,y):\n",
    "    return ((x%y) == 0)\n",
    "\n",
    "def myPrint(x):\n",
    "    print(x)\n",
    "\n",
    "data = range(2,200)\n",
    "rdd = sc.parallelize(data,4)\n",
    "\n",
    "pivote = 1\n",
    "\n",
    "pivote = rdd.reduce(lambda x,y: x if (x > pivote and x < y) else y)\n",
    "while(pivote != prev):\n",
    "    rdd = rdd.filter(lambda x: (pivote>=x or (x>pivote and not isDivisiblePor(x,pivote)))).cache()\n",
    "    \n",
    "    prev = pivote\n",
    "    pivote = rdd.reduce(lambda x,y: x if (x > pivote and x < y) else y)\n",
    "    \n",
    "    \n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En este ejercicio queremos programar un sistema que recomiende\n",
    "textos a usuarios en base a sus gustos sobre ciertos términos (palabras).\n",
    "Se cuenta con un RDD de textos de la forma (docId, texto) donde texto\n",
    "es un string de longitud variable. Además contamos con un RDD que\n",
    "indica qué términos le gustan o no a cada usuario de la forma (userId,\n",
    "término, score) por ejemplo (23, “calesita”, -2). Se pide programar en\n",
    "Spark un programa que calcule el score total de cada documento para\n",
    "cada usuario generando un RDD de la forma (userId, docId, score) en\n",
    "donde el score es simplemente la suma de los scores del usuario para\n",
    "los términos que aparecen en el documento. Puede haber términos en\n",
    "los documentos para los cuales no exista score de algunos usuarios, en\n",
    "estos casos simplemente los consideramos neutros (score=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2, 16), 1),\n",
       " ((1, 11), -1),\n",
       " ((2, 14), -1),\n",
       " ((5, 13), 5),\n",
       " ((2, 11), 0),\n",
       " ((4, 17), -3),\n",
       " ((3, 13), 3)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = [(11,'Esto es un texto de ejemplo'),\n",
    "          (12,'No tenes creatividad??'),\n",
    "          (13,'No elegir textos aleatorios como lorep isum!!!!'),\n",
    "          (14,'... y no se te cae ni una idea'),\n",
    "          (15,'En el parcial se veia complicad XD'),\n",
    "          (16,'Falta mucho?'),\n",
    "          (17,'Ultimo texto (no puedo poner ni acentos ni la enie porque tengo teclado EEUU)')]\n",
    "\n",
    "terminos = [(1,'esto',-1),\n",
    "            (1,'creatividad',2),\n",
    "            (2,'esto',0),\n",
    "            (2,'falta',1),\n",
    "            (2,'y',-1),\n",
    "            (3,'aleatorios',3),\n",
    "            (3,'como',0),\n",
    "            (4,'puedo',-3),\n",
    "            (5,'textos',5)]\n",
    "\n",
    "def getTermsByDoc(terms,docId):\n",
    "    termsByDoc = []\n",
    "    for term in terms:\n",
    "        termsByDoc.append((term.lower(),docId))\n",
    "    return termsByDoc\n",
    "\n",
    "rddTextos = sc.parallelize(textos)\n",
    "rddTerminos = sc.parallelize(terminos)\n",
    "\n",
    "rddTextos = rddTextos.flatMap(lambda x: getTermsByDoc(x[1].split(),x[0]))\n",
    "#[('esto', 11),\n",
    "#('es', 11),\n",
    "#('un', 11),\n",
    "#('texto', 11),\n",
    "#('de', 11),\n",
    "#('ejemplo', 11),\n",
    "#('no', 12),\n",
    "#('tenes', 12),\n",
    "#('creatividad??', 12),\n",
    "\n",
    "rddTerminos = rddTerminos.map(lambda x: (x[1],(x[0],x[2])))\n",
    "#[('esto', (1, -1)),\n",
    "#('creatividad', (1, 2)),\n",
    "#('esto', (2, 0)),\n",
    "#('falta', (2, 1)),\n",
    "#('y', (2, -1)),\n",
    "#('aleatorios', (3, 3)),\n",
    "#('como', (3, 0)),\n",
    "#('puedo', (4, -3)),\n",
    "#('textos', (5, 5))]\n",
    "\n",
    "rddJoin = rddTextos.join(rddTerminos)\n",
    "#[('falta', (16, (2, 1))),\n",
    "#('y', (14, (2, -1))),\n",
    "#('puedo', (17, (4, -3))),\n",
    "#('como', (13, (3, 0))),\n",
    "#('aleatorios', (13, (3, 3))),\n",
    "#('textos', (13, (5, 5))),\n",
    "#('esto', (11, (1, -1))),\n",
    "#('esto', (11, (2, 0)))]\n",
    "\n",
    "rddJoin.map(lambda x: ((x[1][1][0],x[1][0]),x[1][1][1])).reduceByKey(lambda x,y: x+y).collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
